{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d1aa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set up\n"
     ]
    }
   ],
   "source": [
    "# ATTRIBUTES CLASSIFIER\n",
    "\n",
    "# Imports and Setup\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "from training.train_triplet import TripletModel\n",
    "\n",
    "\n",
    "# Paths\n",
    "root = Path(r\"C:\\Users\\dilku\\deepfashion-recsys\")\n",
    "data_path = root / \"data\" / \"deepfashion_index.csv\"\n",
    "ckpt_path = root / \"checkpoints\" / \"debug-epoch=00-train_loss=0.000-v1.ckpt\"\n",
    "export_dir = root / \"export\"\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Paths set up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808825ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path configured successfully\n",
      "TripletModel imported successfully\n",
      "Fine-tuned model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src folder to path\n",
    "sys.path.append(str(Path(r\"C:\\Users\\dilku\\deepfashion-recsys\\src\")))\n",
    "print(\"Path configured successfully\")\n",
    "\n",
    "# Import TripletModel\n",
    "from training.train_triplet import TripletModel\n",
    "print(\"TripletModel imported successfully\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "ckpt_dir = Path(r\"C:\\Users\\dilku\\deepfashion-recsys\\checkpoints\")\n",
    "ckpt_path = sorted(ckpt_dir.glob(\"*.ckpt\"), key=lambda p: p.stat().st_mtime, reverse=True)[0]\n",
    "\n",
    "\n",
    "# Load the fine-tuned TripletModel\n",
    "from training.train_triplet import TripletModel \n",
    "\n",
    "model = TripletModel.load_from_checkpoint(str(ckpt_path))\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "\n",
    "print(\"Fine-tuned model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca48252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Gallery: 12612 images\n",
      "ðŸ“‚ Query:   14218 images\n"
     ]
    }
   ],
   "source": [
    "# Preparing DataFrames and Transforms\n",
    "df = pd.read_csv(data_path)\n",
    "gallery_df = df[df[\"split\"].str.contains(\"gallery\", case=False)]\n",
    "query_df   = df[df[\"split\"].str.contains(\"query\", case=False)]\n",
    "\n",
    "print(f\"ðŸ“‚ Gallery: {len(gallery_df)} images\")\n",
    "print(f\"ðŸ“‚ Query:   {len(query_df)} images\")\n",
    "\n",
    "img_tfms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c1f3fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12612/12612 [21:44<00:00,  9.67it/s]\n",
      "Extracting embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14218/14218 [21:10<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated and saved\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings using the fine-tuned model\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(image_paths, model):\n",
    "    embs = []\n",
    "    for path in tqdm(image_paths, desc=\"Extracting embeddings\"):\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        x = img_tfms(img).unsqueeze(0).to(\"cpu\")\n",
    "        feat = model(x).cpu().numpy()\n",
    "        embs.append(feat)\n",
    "    return np.concatenate(embs, axis=0)\n",
    "\n",
    "gallery_embs = extract_embeddings(gallery_df[\"image_path\"].tolist(), model)\n",
    "query_embs   = extract_embeddings(query_df[\"image_path\"].tolist(), model)\n",
    "\n",
    "np.save(export_dir / \"gallery_embs_finetuned.npy\", gallery_embs)\n",
    "np.save(export_dir / \"query_embs_finetuned.npy\", query_embs)\n",
    "\n",
    "print(\"Embeddings generated and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40ae5369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned FAISS index saved\n"
     ]
    }
   ],
   "source": [
    "# Build FAISS index for fine-tuned embeddings\n",
    "dim = gallery_embs.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "\n",
    "faiss.normalize_L2(gallery_embs)\n",
    "index.add(gallery_embs.astype(\"float32\"))\n",
    "\n",
    "faiss.write_index(index, str(export_dir / \"faiss_gallery_finetuned.index\"))\n",
    "print(\"Finetuned FAISS index saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62fa9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Scores:\n",
      "Recall@1: 42.82%\n",
      "Recall@5: 62.51%\n",
      "Recall@10: 69.91%\n",
      "Recall@20: 77.11%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Recall@K for Queryâ†’Gallery retrieval\n",
    "def recall_at_k(query_embs, gallery_embs, query_labels, gallery_labels, K=[1,5,10,20]):\n",
    "    faiss.normalize_L2(query_embs)\n",
    "    D, I = index.search(query_embs.astype(\"float32\"), max(K))\n",
    "    recalls = {}\n",
    "    for k in K:\n",
    "        matches = (gallery_labels[I[:, :k]] == query_labels[:, None])\n",
    "        recalls[k] = (matches.any(axis=1).mean()) * 100\n",
    "    return recalls\n",
    "\n",
    "recalls = recall_at_k(\n",
    "    query_embs,\n",
    "    gallery_embs,\n",
    "    query_df[\"item_id\"].to_numpy(),\n",
    "    gallery_df[\"item_id\"].to_numpy()\n",
    ")\n",
    "\n",
    "print(\"Recall Scores:\")\n",
    "for k, v in recalls.items():\n",
    "    print(f\"Recall@{k}: {v:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4b40a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fine-tuning and retrieval evaluation completed successfully.\n",
      "Generated files:\n",
      " - fine_tuned_gallery_embs.npy\n",
      " - fine_tuned_query_embs.npy\n",
      " - faiss_gallery_finetuned.index\n",
      "\n",
      "Next steps:\n",
      " - Compare these Recall@K results with the baseline model to measure improvement.\n",
      " - Document performance changes in the README (e.g., Recall@10 increased from 88% â†’ 94%).\n"
     ]
    }
   ],
   "source": [
    "print(\"Model fine-tuning and retrieval evaluation completed successfully.\")\n",
    "print(\"Generated files:\")\n",
    "print(\" - fine_tuned_gallery_embs.npy\")\n",
    "print(\" - fine_tuned_query_embs.npy\")\n",
    "print(\" - faiss_gallery_finetuned.index\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\" - Compare these Recall@K results with the baseline model to measure improvement.\")\n",
    "print(\" - Document performance changes in the README (e.g., Recall@10 increased from 88% â†’ 94%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9de113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dfashion)",
   "language": "python",
   "name": "dfashion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
